<div align="center">
<h1>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</h1>
  <div align="center">
</div>
<h3><h3>
</div>

<div align="center">
  <img src="figures/teaser.png" width="100%" ></img>
  <br>
  <em>
      The reasoning model, after the length-compressible CoT tuning, can generate reasoning paths from long to short, leveraging LoRA as a `Valve'.
  </em>
</div>
<br>

> [Xinyin Ma](https://horseee.github.io/)\*, [Guangnian Wan]()\*, [Runpeng Yu](), [Gongfan Fang](https://fangggf.github.io/), [Xinchao Wang](https://sites.google.com/site/sitexinchaowang/)   
> [Learning and Vision Lab](http://lv-nus.org/), National University of Singapore  
> ðŸ¥¯[[Arxiv]](https://arxiv.org/abs/)  ðŸŽ„[[Dataset]]()   
> \* Equal Contribution

### TODO
- [ ] Release the dataset
- [ ] Release the model
- [ ] Release the trainng code

### Datasets


### Training Code


### Models


